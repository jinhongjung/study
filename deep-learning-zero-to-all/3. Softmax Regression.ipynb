{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on Softmax Regression using TensorFlow\n",
    "\n",
    "In this section, we will impement Softmax Regression using TensorFlow. \n",
    "Softmax Regression is a multinomial algorithm which classifies multi-class labels. \n",
    "Given a data point $\\mathbf{x} \\in \\mathbb{R}^{d}$, the hypothesis of Softmax Regression is defined as follows:\n",
    "\n",
    "$$ H(\\mathbf{x}) = \\mathbf{Wx + b}$$\n",
    "\n",
    "where $\\mathbf{W} \\in \\mathbb{R}^{d \\times d}$ is an weight matrix to be learned, and $d$ is the number of features.\n",
    "In this case, the returned values are in a $d$-dimensional vector, and the vector is called a signal of the data point $\\mathbf{x}$. \n",
    "To make the signal probabilistic, we need to pass it to softmax function which is defined as follows:\n",
    "\n",
    "$$ S(y_{i}) = \\frac{e^{y_{i}}}{\\sum_{j}e^{y_j}}$$\n",
    "\n",
    "The loss function of Softmax Regression for a signal is represented as follows:\n",
    "\n",
    "$$ D(S, L) = -\\sum_{i}L_{i}log(S_i)$$\n",
    "\n",
    "where $S$ is a softmax vector, and $L$ is the label vector encoded by one-hot vector. \n",
    "The loss function is called cross-entory function (generalized version of logistic function).\n",
    "Hence, the final loss function for a dataset is the average of the loss for each data point as:\n",
    "\n",
    "$$\\mathcal{L}(X) = \\frac{1}{N}\\sum_{i} D(S(H(X_{i}), L_{i})$$\n",
    "\n",
    "The following code implements Softmax Regression using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.63772\n",
      "100 0.64858\n",
      "200 0.568961\n",
      "300 0.511829\n",
      "400 0.461085\n",
      "500 0.412936\n",
      "600 0.36592\n",
      "700 0.319551\n",
      "800 0.27495\n",
      "900 0.242613\n",
      "1000 0.229299\n",
      "1100 0.218094\n",
      "1200 0.207919\n",
      "1300 0.198633\n",
      "1400 0.190123\n",
      "1500 0.182293\n",
      "1600 0.175065\n",
      "1700 0.168373\n",
      "1800 0.16216\n",
      "1900 0.156376\n",
      "2000 0.150978\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# set values\n",
    "N = len(x_data) # number of instances\n",
    "F = 4 # number of features\n",
    "C = 3 # number of classes\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, F])\n",
    "Y = tf.placeholder(tf.int32, shape=[None, C])\n",
    "W = tf.Variable(tf.random_normal([F, C]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([C]), name='bias')\n",
    "\n",
    "# set hypothesis\n",
    "H = tf.matmul(X, W) + b # hypothesis\n",
    "S = tf.nn.softmax(H) # signal\n",
    "\n",
    "# set loss function\n",
    "loss_i = tf.nn.softmax_cross_entropy_with_logits(logits=H, labels=Y)\n",
    "loss = tf.reduce_mean(loss_i) \n",
    "#loss = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(S), axis=1)) / N # the above is the same as this\n",
    "\n",
    "# set train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "# training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2001):\n",
    "        loss_val, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, loss_val)\n",
    "\n",
    "    # testing\n",
    "    s_val = sess.run(S, feed_dict={X: [[1, 11, 7, 9],\n",
    "                                        [1, 3, 4, 3]]})\n",
    "    c = sess.run(tf.argmax(s_val, 1))\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Softmax Regression with Real-world dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11.4009 0.19802\n",
      "100 0.896816 0.712871\n",
      "200 0.595756 0.831683\n",
      "300 0.442951 0.861386\n",
      "400 0.345247 0.871287\n",
      "500 0.277158 0.910891\n",
      "600 0.228423 0.930693\n",
      "700 0.192996 0.950495\n",
      "800 0.166649 0.960396\n",
      "900 0.146478 0.960396\n",
      "1000 0.130581 0.990099\n",
      "1100 0.117726 0.990099\n",
      "1200 0.10711 0.990099\n",
      "1300 0.0981921 0.990099\n",
      "1400 0.0905944 0.990099\n",
      "1500 0.0840464 1.0\n",
      "1600 0.0783481 1.0\n",
      "1700 0.0733475 1.0\n",
      "1800 0.0689274 1.0\n",
      "1900 0.064995 1.0\n",
      "2000 0.0614763 1.0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('datasets/data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]] # in this case, y_data is not one-hot encoded\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "# set values\n",
    "N = len(x_data) # number of instances\n",
    "F = 16 # number of features\n",
    "C = 7 # number of classes\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, F])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])\n",
    "Y_one_hot = tf.one_hot(Y, C) #shape=(?, 1, 7) see the refernece of one_hot\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, C]) #shape=(?, 7)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([F, C]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([C]), name='bias')\n",
    "\n",
    "logits = tf.matmul(X, W) + b\n",
    "H = tf.nn.softmax(logits)\n",
    "\n",
    "loss_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_one_hot)\n",
    "loss = tf.reduce_mean(loss_i)\n",
    "\n",
    "# set train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(H, 1)\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(2001):\n",
    "        loss_val, acc, _ = sess.run([loss, accuracy, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if i % 100 == 0:\n",
    "            print(i, loss_val, acc)\n",
    "            \n",
    "    pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p==int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
