{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning for Improving Generalized Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing for Gradient Descent\n",
    "\n",
    "We preprocess the data using the following normalization (standardization):\n",
    "\n",
    "$$ x_j' = \\frac{x_j - \\mu_j}{\\sigma_{j}} $$\n",
    "\n",
    "Also, we need to look into the unit of a feature if your gradient behavior is against your expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  0001 cost =  1.187334335\n",
      "Epoch:  0002 cost =  0.592843584\n",
      "Epoch:  0003 cost =  0.502938267\n",
      "Epoch:  0004 cost =  0.454558649\n",
      "Epoch:  0005 cost =  0.423473037\n",
      "Epoch:  0006 cost =  0.400738826\n",
      "Epoch:  0007 cost =  0.381952957\n",
      "Epoch:  0008 cost =  0.368761120\n",
      "Epoch:  0009 cost =  0.356245184\n",
      "Epoch:  0010 cost =  0.346943913\n",
      "Epoch:  0011 cost =  0.338018738\n",
      "Epoch:  0012 cost =  0.330490313\n",
      "Epoch:  0013 cost =  0.324368779\n",
      "Epoch:  0014 cost =  0.318709040\n",
      "Epoch:  0015 cost =  0.313496173\n",
      "Accuracy:  0.9112\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "H = tf.matmul(X, W) + b\n",
    "S = tf.nn.softmax(H)\n",
    "\n",
    "loss_i = tf.nn.softmax_cross_entropy_with_logits(logits=H, labels=Y)\n",
    "loss = tf.reduce_mean(loss_i) \n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss)\n",
    "\n",
    "is_correct = tf.equal(tf.arg_max(S, 1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# one epoch = one forward pass and backward pass of all training instance\n",
    "# batch size = the number of training examples in one f/b pass\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([loss, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch: ', '%04d' % (epoch + 1), \"cost = \", '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print(\"Accuracy: \", accuracy.eval(session=sess, \n",
    "                                  feed_dict={X: mnist.test.images, Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image show and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12cc715f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "print(\"Prediction:\", sess.run(tf.argmax(S, 1), \n",
    "                            feed_dict={X: mnist.test.images[r:r+1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28), cmap=\"Greys\", interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
